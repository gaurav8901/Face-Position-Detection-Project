{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face position detection using ML Algorithms .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaurav8901/Machine-Learning-/blob/main/Face_position_detection_using_ML_Algorithms_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXdVeGJRxiPk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import plotly.express as px\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/dataset_1.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cTPsESiwSsW",
        "outputId": "6ce69ad5-0e00-44eb-8609-b407ede60220"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNVwke97Wjaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787abfd0-7b3a-4f08-98cd-da15c2d7efad"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 606 entries, 0 to 605\n",
            "Data columns (total 19 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   fileName  606 non-null    object\n",
            " 1   subject   606 non-null    int64 \n",
            " 2   imgNum    606 non-null    int64 \n",
            " 3   label     606 non-null    int64 \n",
            " 4   ang       606 non-null    int64 \n",
            " 5   xF        606 non-null    int64 \n",
            " 6   yF        606 non-null    int64 \n",
            " 7   wF        606 non-null    int64 \n",
            " 8   hF        606 non-null    int64 \n",
            " 9   xRE       606 non-null    int64 \n",
            " 10  yRE       606 non-null    int64 \n",
            " 11  xLE       606 non-null    int64 \n",
            " 12  yLE       606 non-null    int64 \n",
            " 13  xN        606 non-null    int64 \n",
            " 14  yN        606 non-null    int64 \n",
            " 15  xRM       606 non-null    int64 \n",
            " 16  yRM       606 non-null    int64 \n",
            " 17  xLM       606 non-null    int64 \n",
            " 18  yLM       606 non-null    int64 \n",
            "dtypes: int64(18), object(1)\n",
            "memory usage: 90.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Gml0rPWlq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c364e412-06e3-4278-d656-3e6169bbb3df"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(606, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvMhuXaZWqT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8104856b-d544-4261-abf1-a582acb23db2"
      },
      "source": [
        "print(\"No of classes in the dataset\", dataset['label'].unique())\n",
        "print(\"No of unique values in the angle colume\", dataset['ang'].unique())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of classes in the dataset [2 1 3]\n",
            "No of unique values in the angle colume [  0 -15 -30 -45  15  30  45]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apAtBT36Ww3l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e6950676-2de8-43ae-fb49-34163a3225f9"
      },
      "source": [
        "dataset.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fileName</th>\n",
              "      <th>subject</th>\n",
              "      <th>imgNum</th>\n",
              "      <th>label</th>\n",
              "      <th>ang</th>\n",
              "      <th>xF</th>\n",
              "      <th>yF</th>\n",
              "      <th>wF</th>\n",
              "      <th>hF</th>\n",
              "      <th>xRE</th>\n",
              "      <th>yRE</th>\n",
              "      <th>xLE</th>\n",
              "      <th>yLE</th>\n",
              "      <th>xN</th>\n",
              "      <th>yN</th>\n",
              "      <th>xRM</th>\n",
              "      <th>yRM</th>\n",
              "      <th>xLM</th>\n",
              "      <th>yLM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20130529_01_Driv_001_f</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>292</td>\n",
              "      <td>209</td>\n",
              "      <td>100</td>\n",
              "      <td>112</td>\n",
              "      <td>323</td>\n",
              "      <td>232</td>\n",
              "      <td>367</td>\n",
              "      <td>231</td>\n",
              "      <td>353</td>\n",
              "      <td>254</td>\n",
              "      <td>332</td>\n",
              "      <td>278</td>\n",
              "      <td>361</td>\n",
              "      <td>278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20130529_01_Driv_002_f</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>286</td>\n",
              "      <td>200</td>\n",
              "      <td>109</td>\n",
              "      <td>128</td>\n",
              "      <td>324</td>\n",
              "      <td>235</td>\n",
              "      <td>366</td>\n",
              "      <td>235</td>\n",
              "      <td>353</td>\n",
              "      <td>258</td>\n",
              "      <td>333</td>\n",
              "      <td>281</td>\n",
              "      <td>361</td>\n",
              "      <td>281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20130529_01_Driv_003_f</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>290</td>\n",
              "      <td>204</td>\n",
              "      <td>105</td>\n",
              "      <td>121</td>\n",
              "      <td>325</td>\n",
              "      <td>240</td>\n",
              "      <td>367</td>\n",
              "      <td>239</td>\n",
              "      <td>351</td>\n",
              "      <td>260</td>\n",
              "      <td>334</td>\n",
              "      <td>282</td>\n",
              "      <td>362</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20130529_01_Driv_004_f</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>287</td>\n",
              "      <td>202</td>\n",
              "      <td>112</td>\n",
              "      <td>118</td>\n",
              "      <td>325</td>\n",
              "      <td>230</td>\n",
              "      <td>369</td>\n",
              "      <td>230</td>\n",
              "      <td>353</td>\n",
              "      <td>253</td>\n",
              "      <td>335</td>\n",
              "      <td>274</td>\n",
              "      <td>362</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20130529_01_Driv_005_f</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>290</td>\n",
              "      <td>193</td>\n",
              "      <td>104</td>\n",
              "      <td>119</td>\n",
              "      <td>325</td>\n",
              "      <td>224</td>\n",
              "      <td>366</td>\n",
              "      <td>225</td>\n",
              "      <td>353</td>\n",
              "      <td>244</td>\n",
              "      <td>333</td>\n",
              "      <td>268</td>\n",
              "      <td>363</td>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 fileName  subject  imgNum  label  ang  ...   yN  xRM  yRM  xLM  yLM\n",
              "0  20130529_01_Driv_001_f        1       1      2    0  ...  254  332  278  361  278\n",
              "1  20130529_01_Driv_002_f        1       2      2    0  ...  258  333  281  361  281\n",
              "2  20130529_01_Driv_003_f        1       3      2    0  ...  260  334  282  362  282\n",
              "3  20130529_01_Driv_004_f        1       4      2    0  ...  253  335  274  362  275\n",
              "4  20130529_01_Driv_005_f        1       5      2    0  ...  244  333  268  363  268\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0g2fu0xWr-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5c6e4b-f208-4356-fd84-e62f8d77fa65"
      },
      "source": [
        "print(\"Unique angle class:\", dataset['ang'].unique())\n",
        "angle = dataset['ang']\n",
        "angle = np.array(angle)\n",
        "for i in range(0, angle.shape[0]):\n",
        "  if(angle[i]==(-15)):\n",
        "    angle[i] = 1\n",
        "  if(angle[i]==(-30)):\n",
        "    angle[i] = 2\n",
        "  if(angle[i]==(-45)):\n",
        "    angle[i] = 3\n",
        "  if(angle[i]==(15)):\n",
        "    angle[i] = 4\n",
        "  if(angle[i]==(30)):\n",
        "    angle[i] = 5\n",
        "  if(angle[i]==(45)):\n",
        "    angle[i] = 6"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique angle class: [  0 -15 -30 -45  15  30  45]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6cBYZZqZza2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7d806d-2c35-4653-c5be-74035f287f59"
      },
      "source": [
        "angle"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 2, 2, 3, 3, 3, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 4, 5, 6, 6, 5, 5, 4, 4, 4, 4, 5, 6, 6, 5, 4, 4, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 4, 4, 4, 4, 4, 4, 4, 4, 5,\n",
              "       6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbpyH2GHW4S4"
      },
      "source": [
        "# drop fileName\tsubject\timgNum\tlabel\tang\n",
        "dataset = dataset.drop(['fileName', 'subject', 'imgNum', 'ang'], axis = 1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljtPaC0fW7vO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "12aee487-ed30-4696-9079-84629061c768"
      },
      "source": [
        "dataset.head(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>xF</th>\n",
              "      <th>yF</th>\n",
              "      <th>wF</th>\n",
              "      <th>hF</th>\n",
              "      <th>xRE</th>\n",
              "      <th>yRE</th>\n",
              "      <th>xLE</th>\n",
              "      <th>yLE</th>\n",
              "      <th>xN</th>\n",
              "      <th>yN</th>\n",
              "      <th>xRM</th>\n",
              "      <th>yRM</th>\n",
              "      <th>xLM</th>\n",
              "      <th>yLM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>292</td>\n",
              "      <td>209</td>\n",
              "      <td>100</td>\n",
              "      <td>112</td>\n",
              "      <td>323</td>\n",
              "      <td>232</td>\n",
              "      <td>367</td>\n",
              "      <td>231</td>\n",
              "      <td>353</td>\n",
              "      <td>254</td>\n",
              "      <td>332</td>\n",
              "      <td>278</td>\n",
              "      <td>361</td>\n",
              "      <td>278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>286</td>\n",
              "      <td>200</td>\n",
              "      <td>109</td>\n",
              "      <td>128</td>\n",
              "      <td>324</td>\n",
              "      <td>235</td>\n",
              "      <td>366</td>\n",
              "      <td>235</td>\n",
              "      <td>353</td>\n",
              "      <td>258</td>\n",
              "      <td>333</td>\n",
              "      <td>281</td>\n",
              "      <td>361</td>\n",
              "      <td>281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>290</td>\n",
              "      <td>204</td>\n",
              "      <td>105</td>\n",
              "      <td>121</td>\n",
              "      <td>325</td>\n",
              "      <td>240</td>\n",
              "      <td>367</td>\n",
              "      <td>239</td>\n",
              "      <td>351</td>\n",
              "      <td>260</td>\n",
              "      <td>334</td>\n",
              "      <td>282</td>\n",
              "      <td>362</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>287</td>\n",
              "      <td>202</td>\n",
              "      <td>112</td>\n",
              "      <td>118</td>\n",
              "      <td>325</td>\n",
              "      <td>230</td>\n",
              "      <td>369</td>\n",
              "      <td>230</td>\n",
              "      <td>353</td>\n",
              "      <td>253</td>\n",
              "      <td>335</td>\n",
              "      <td>274</td>\n",
              "      <td>362</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>290</td>\n",
              "      <td>193</td>\n",
              "      <td>104</td>\n",
              "      <td>119</td>\n",
              "      <td>325</td>\n",
              "      <td>224</td>\n",
              "      <td>366</td>\n",
              "      <td>225</td>\n",
              "      <td>353</td>\n",
              "      <td>244</td>\n",
              "      <td>333</td>\n",
              "      <td>268</td>\n",
              "      <td>363</td>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label   xF   yF   wF   hF  xRE  yRE  xLE  yLE   xN   yN  xRM  yRM  xLM  yLM\n",
              "0      2  292  209  100  112  323  232  367  231  353  254  332  278  361  278\n",
              "1      2  286  200  109  128  324  235  366  235  353  258  333  281  361  281\n",
              "2      2  290  204  105  121  325  240  367  239  351  260  334  282  362  282\n",
              "3      2  287  202  112  118  325  230  369  230  353  253  335  274  362  275\n",
              "4      2  290  193  104  119  325  224  366  225  353  244  333  268  363  268"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6i7LgkcXAZA"
      },
      "source": [
        "y = np.array(dataset['label'])\n",
        "# drop the label colume\n",
        "dataset = dataset.drop(['label'], axis = 1)\n",
        "x = np.array(dataset)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEfvqakTgaOc"
      },
      "source": [
        "# min max scaling the dataset\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x)\n",
        "x = scaler.transform(x)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx2lQLE5Y4qU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4b495d-1edf-4120-eb16-0063980ddcb8"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(606, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KDga4ViY5qx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2720da0b-705c-4bbb-b099-f79ef03116bb"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(606,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkmdHwxMU8ef"
      },
      "source": [
        "# 5 fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR3rSYunYfcF"
      },
      "source": [
        "# shuffel the dataset\n",
        "x, y = shuffle(x, y, random_state=100)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWxrzkreg64O"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "def fold(features,y_actual):\n",
        "  kf = KFold(n_splits=5,random_state=1000, shuffle=True)\n",
        "  kf.get_n_splits(features)\n",
        "  print(kf)\n",
        "  all_x_train = []\n",
        "  all_x_test = []\n",
        "  all_y_train = []\n",
        "  all_y_test = []\n",
        "  for train_index, test_index in kf.split(features):\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = y_actual[train_index], y_actual[test_index]\n",
        "    all_x_train.append(X_train)\n",
        "    all_x_test.append(X_test)\n",
        "    all_y_train.append(y_train)\n",
        "    all_y_test.append(y_test)\n",
        "  all_x_train, all_x_test, all_y_train, all_y_test  = np.array(all_x_train), np.array(all_x_test), np.array(all_y_train), np.array(all_y_test)\n",
        "  return all_x_train, all_x_test, all_y_train, all_y_test"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoimdvJqZYhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8860f18-1753-45df-a132-7f7891579948"
      },
      "source": [
        "all_x_train, all_x_test, all_y_train, all_y_test = fold(x, y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KFold(n_splits=5, random_state=1000, shuffle=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7gfszpMXCed"
      },
      "source": [
        "# Classification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEljlPHbxVjG"
      },
      "source": [
        "X_train, X_validation, y_train, y_validation = train_test_split(all_x_train[0], all_y_train[0], test_size=0.20, random_state=42)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZVpO_YmU-I_"
      },
      "source": [
        "## Logistic Regression\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_GY3NJlxzRV"
      },
      "source": [
        "# hyperparameter tuning for logistic accuracy\n",
        "def logistic_hyperparameter_tuning(epoch, alpha, roh, n_iter_no_change, X_train, X_validation, y_train, y_validation):\n",
        "  val_acc = []\n",
        "  train_acc = []\n",
        "  for i in range(0, epoch.shape[0]):\n",
        "    # we are taking logloss function for error calculation\n",
        "    logistic_reg_classifier = OneVsRestClassifier(SGDClassifier(loss = 'log', alpha = alpha[i], fit_intercept = True, max_iter = epoch[i], tol = roh[i], n_iter_no_change = n_iter_no_change[i])).fit(X_train, y_train)\n",
        "    predicted = logistic_reg_classifier.predict(X_validation)\n",
        "    val_acc.append(accuracy_score(y_validation, predicted)*100)\n",
        "    train_pred = logistic_reg_classifier.predict(X_train)\n",
        "    train_acc.append(accuracy_score(y_train, train_pred)*100)\n",
        "  # Get the maximum accuracy on validation\n",
        "  print(\"Train Accuracy: \", train_acc)\n",
        "  print(\"Validation Accuracy\", val_acc)\n",
        "  max_value = max(val_acc)\n",
        "  max_index = val_acc.index(max_value)\n",
        "  best_hyperparameter = (epoch[max_index], alpha[max_index], roh[max_index], n_iter_no_change[max_index])\n",
        "  print(\"Best Hyperparameter:\")\n",
        "  print(\"Epoch = \", epoch[max_index])\n",
        "  print(\"Alpha = \", alpha[max_index])\n",
        "  print(\"Roh = \", roh[max_index])\n",
        "  print(\"n_iter_no_change (Number of iterations with no improvement) = \", n_iter_no_change[max_index])\n",
        "  return best_hyperparameter"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peBNtkH_x351",
        "outputId": "73f692ca-bf32-40ba-ab7f-2203a36ecea8"
      },
      "source": [
        "epoch = np.array([100, 150, 200, 250, 300, 350, 400, 450, 500, 550])\n",
        "alpha = np.array([0.01, 0.001, 0.0001, 0.00001, 0.125, 0.15, 0.18, 0.2, 0.25, 0.3])\n",
        "roh = np.array([0.00001, 0.00001, 0.000001, 0.0000001, 0.000001, 0.0001, 0.0001, 0.0001, 0.0001, 0.000001])\n",
        "n_iter_no_change = np.array([8, 9, 10, 11, 12, 13, 14, 15, 16, 18])\n",
        "epoch, alpha, roh, n_iter_no_change = logistic_hyperparameter_tuning(epoch, alpha, roh, n_iter_no_change, X_train, X_validation, y_train, y_validation)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy:  [90.95607235142118, 91.21447028423772, 92.24806201550388, 95.34883720930233, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118]\n",
            "Validation Accuracy [89.69072164948454, 89.69072164948454, 93.81443298969072, 91.75257731958763, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454]\n",
            "Best Hyperparameter:\n",
            "Epoch =  200\n",
            "Alpha =  0.0001\n",
            "Roh =  1e-06\n",
            "n_iter_no_change (Number of iterations with no improvement) =  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfMLPNfqZEps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411b8790-1bce-4a5a-c746-8cc94d9a1dc8"
      },
      "source": [
        "# for testing delete this shell\n",
        "for i in range(0, 5): # for 5 fold\n",
        "  print(\"For fold no:\", i+1)\n",
        "  print(\"-\"*100)\n",
        "  logistic_regression = OneVsRestClassifier(SGDClassifier(loss = 'log', alpha = alpha, fit_intercept = True,\\\n",
        "                                                          max_iter = epoch, tol = roh, n_iter_no_change = n_iter_no_change,\\\n",
        "                                                          verbose= False))\n",
        "  logistic_regression.fit(all_x_train[i], all_y_train[i])\n",
        "  print(\"Accuracy on training data: \" + str(logistic_regression.score(all_x_train[i], all_y_train[i])*100) + \"%\")\n",
        "  predicted = logistic_regression.predict(all_x_test[i])\n",
        "  print(\"Testing Accuracy Score: \" + str(accuracy_score(all_y_test[i], predicted)*100))\n",
        "  print(\"Confusion Matrix : \\n\" + str(confusion_matrix(all_y_test[i], predicted)))\n",
        "  print(\"Classification Report for 6-classes: \")\n",
        "  # out_labels = [1, 2, 3, 4, 5, 6]\n",
        "  print(classification_report(all_y_test[i], predicted, digits=4))\n",
        "  print(\"-\"*100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For fold no: 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 93.80165289256198%\n",
            "Testing Accuracy Score: 89.34426229508196\n",
            "Confusion Matrix : \n",
            "[[  2   5   0]\n",
            " [  1 106   0]\n",
            " [  0   7   1]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.6667    0.2857    0.4000         7\n",
            "           2     0.8983    0.9907    0.9422       107\n",
            "           3     1.0000    0.1250    0.2222         8\n",
            "\n",
            "    accuracy                         0.8934       122\n",
            "   macro avg     0.8550    0.4671    0.5215       122\n",
            "weighted avg     0.8917    0.8934    0.8639       122\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 92.57731958762886%\n",
            "Testing Accuracy Score: 95.86776859504133\n",
            "Confusion Matrix : \n",
            "[[  2   3   0]\n",
            " [  0 112   0]\n",
            " [  0   2   2]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     1.0000    0.4000    0.5714         5\n",
            "           2     0.9573    1.0000    0.9782       112\n",
            "           3     1.0000    0.5000    0.6667         4\n",
            "\n",
            "    accuracy                         0.9587       121\n",
            "   macro avg     0.9858    0.6333    0.7388       121\n",
            "weighted avg     0.9604    0.9587    0.9511       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 94.02061855670102%\n",
            "Testing Accuracy Score: 93.38842975206612\n",
            "Confusion Matrix : \n",
            "[[  3   2   0]\n",
            " [  1 109   0]\n",
            " [  0   5   1]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7500    0.6000    0.6667         5\n",
            "           2     0.9397    0.9909    0.9646       110\n",
            "           3     1.0000    0.1667    0.2857         6\n",
            "\n",
            "    accuracy                         0.9339       121\n",
            "   macro avg     0.8966    0.5859    0.6390       121\n",
            "weighted avg     0.9348    0.9339    0.9186       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 92.98969072164948%\n",
            "Testing Accuracy Score: 92.56198347107438\n",
            "Confusion Matrix : \n",
            "[[  2   2   0]\n",
            " [  1 109   0]\n",
            " [  0   6   1]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.6667    0.5000    0.5714         4\n",
            "           2     0.9316    0.9909    0.9604       110\n",
            "           3     1.0000    0.1429    0.2500         7\n",
            "\n",
            "    accuracy                         0.9256       121\n",
            "   macro avg     0.8661    0.5446    0.5939       121\n",
            "weighted avg     0.9268    0.9256    0.9064       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 92.78350515463917%\n",
            "Testing Accuracy Score: 90.9090909090909\n",
            "Confusion Matrix : \n",
            "[[  2   4   0]\n",
            " [  0 107   0]\n",
            " [  0   7   1]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     1.0000    0.3333    0.5000         6\n",
            "           2     0.9068    1.0000    0.9511       107\n",
            "           3     1.0000    0.1250    0.2222         8\n",
            "\n",
            "    accuracy                         0.9091       121\n",
            "   macro avg     0.9689    0.4861    0.5578       121\n",
            "weighted avg     0.9176    0.9091    0.8806       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic8MWiLuyZbo",
        "outputId": "f056b394-45f4-47b3-9050-643d7fef5091"
      },
      "source": [
        "logistic_regression = OneVsRestClassifier(SGDClassifier(loss = 'log', alpha = alpha, fit_intercept = True, max_iter = epoch, tol = roh, n_iter_no_change = n_iter_no_change))\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "print(\"Accuracy on training data: \" + str(logistic_regression.score(X_train, y_train)*100) + \"%\")\n",
        "print(\"-\"*100)\n",
        "test_predicted = logistic_regression.predict(all_x_test[0])\n",
        "print(\"Testing Accuracy Score: \" + str(accuracy_score(all_y_test[0], test_predicted)*100))\n",
        "print(\"Testing Confusion Matrix : \\n\" + str(confusion_matrix(all_y_test[0], test_predicted)))\n",
        "print(\"-\"*100)\n",
        "valid_predicted = logistic_regression.predict(X_validation)\n",
        "print(\"Validation Accuracy Score: \" + str(accuracy_score(y_validation, valid_predicted)*100))\n",
        "print(\"Validation Confusion Matrix : \\n\" + str(confusion_matrix(y_validation, valid_predicted)))\n",
        "print(\"-\"*100)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training data: 95.09043927648578%\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Testing Accuracy Score: 94.26229508196722\n",
            "Testing Confusion Matrix : \n",
            "[[  1   6   0]\n",
            " [  0 107   0]\n",
            " [  0   1   7]]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Validation Accuracy Score: 93.81443298969072\n",
            "Validation Confusion Matrix : \n",
            "[[ 2  6  0]\n",
            " [ 0 87  0]\n",
            " [ 0  0  2]]\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNDsaYHYVHIO"
      },
      "source": [
        "# Single Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbnAgZm8dm-7"
      },
      "source": [
        "# it's slp\n",
        "class SingleLayerPerceptron():\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        return self.predict_(self.add_bias(X))\n",
        "    \n",
        "    def predict_(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        pre_vals = np.dot(X, self.weights.T).reshape(-1,len(self.classes))\n",
        "        return self.softmax(pre_vals)\n",
        "    \n",
        "    def softmax(self, z):\n",
        "        \"\"\"\n",
        "        z: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
        "\n",
        "    def predict_classes(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        self.probs_ = self.predict(X)\n",
        "        return np.vectorize(lambda c: self.classes[c])(np.argmax(self.probs_, axis=1))\n",
        "  \n",
        "    def add_bias(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        return np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "    def one_hot(self, y):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.eye(len(self.classes))[np.vectorize(lambda c: self.class_labels[c])(y).reshape(-1)]\n",
        "    \n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(self.predict_classes(X) == y)\n",
        "    \n",
        "    def evaluate_(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(np.argmax(self.predict_(X), axis=1) == np.argmax(y, axis=1))\n",
        "\n",
        "    def logloss(self, y, probs):\n",
        "        \"\"\"\n",
        "        y:      1D array of shape (no of patterns, )\n",
        "        probs:  1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(-y*np.log(probs) - (1-y)*np.log(1-probs))\n",
        "\n",
        "    def cross_entropy(self, y, probs):\n",
        "        \"\"\"\n",
        "        y:      1D array of shape (no of patterns, )\n",
        "        probs:  1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return -1 * np.mean(y * np.log(probs))\n",
        "\n",
        "    def mse(self, y, probs):\n",
        "        \"\"\"\n",
        "        y:      1D array of shape (no of patterns, )\n",
        "        probs:  1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return (((y - probs)**2).mean())/2\n",
        "        \n",
        "    def fit(self, X, y, epoch, roh, lr):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        epoch:  int, convergence criteria (hyperparameter)\n",
        "        roh:    float, convergence criteria (hyperparameter)\n",
        "        lr:     float, learning rate (hyperparameter)\n",
        "        \"\"\"\n",
        "        self.epoch = epoch\n",
        "        self.roh = roh\n",
        "        self.lr = lr \n",
        "        self.classes = np.unique(y)\n",
        "        self.class_labels = {c:i for i,c in enumerate(self.classes)}\n",
        "        X = self.add_bias(X)\n",
        "        y = self.one_hot(y)\n",
        "        self.loss = []\n",
        "        self.weights = np.zeros(shape=(len(self.classes),X.shape[1]))*0.1\n",
        "        self.fit_data(X, y)\n",
        "        return self\n",
        " \n",
        "    def fit_data(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        itr = 0\n",
        "        while (not self.epoch or itr < self.epoch):\n",
        "            self.loss.append(self.mse(y, self.predict_(X)))\n",
        "            # put the thershold function on the predicted value i.e. here self.predict_(X)\n",
        "            temp = self.predict_(X)\n",
        "            # threshold activation on the predicted value of all patterns\n",
        "            for k in range(0, temp.shape[0]):\n",
        "              for j in range(0, temp.shape[1]):\n",
        "                if(temp[k][j]>=0.5):\n",
        "                  temp[k][j] = 1\n",
        "                else:\n",
        "                  temp[k][j] = 0\n",
        "            #print(\"Iteration: \", itr+1, \" Mse: \", self.mse(y, self.predict_(X)))\n",
        "            error = y - temp\n",
        "            update = (self.lr * np.dot(error.T, X))\n",
        "            self.weights += update\n",
        "            if np.abs(update).max() < self.roh:\n",
        "              print(\"Converged through roh criteria.\")\n",
        "              break\n",
        "            itr +=1\n",
        "        if(itr==self.epoch):\n",
        "          print(\"Converged through maximum of Iteration:\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHRm2tSRyr7r"
      },
      "source": [
        "def slp_hyperparameter_tuning(epoch, alpha, roh, X_train, X_validation, y_train, y_validation):\n",
        "  val_acc = []\n",
        "  train_acc = []\n",
        "  for i in range(0, epoch.shape[0]):\n",
        "    # we are taking logloss function for error calculation\n",
        "    slp_classifier = SingleLayerPerceptron().fit(X_train, y_train, epoch = epoch[i], roh = roh[i], lr = alpha[i])\n",
        "    predicted = slp_classifier.predict_classes(X_validation)\n",
        "    val_acc.append(accuracy_score(y_validation, predicted)*100)\n",
        "    train_predicted = slp_classifier.predict_classes(X_train)\n",
        "    train_acc.append(accuracy_score(y_train, train_predicted)*100)\n",
        "  # Get the maximum accuracy on validation\n",
        "  print(\"Training Accuracy: \", train_acc)\n",
        "  print(\"Validation Accuracy: \", val_acc)\n",
        "  max_value = max(val_acc)\n",
        "  max_index = val_acc.index(max_value)\n",
        "  best_hyperparameter = (epoch[max_index], alpha[max_index], roh[max_index])\n",
        "  print(\"Best Hyperparameter:\")\n",
        "  print(\"Epoch = \", epoch[max_index])\n",
        "  print(\"Alpha = \", alpha[max_index])\n",
        "  print(\"Roh = \", roh[max_index])\n",
        "  return best_hyperparameter"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeiWD0KgyvIT",
        "outputId": "7b4fb493-99dd-446a-e792-2512d79f4517"
      },
      "source": [
        "epoch = np.array([100, 150, 200, 250, 300, 350, 400, 450, 500, 550])\n",
        "alpha = np.array([0.0001, 0.0001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.0001, 0.0001])\n",
        "roh = np.array([0.00001, 0.00001, 0.000001, 0.0000001, 0.000001, 0.0001, 0.0001, 0.0001, 0.0001, 0.000001])\n",
        "epoch, alpha, roh = slp_hyperparameter_tuning(epoch, alpha, roh, X_train, X_validation, y_train, y_validation)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Training Accuracy:  [90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 93.02325581395348, 92.76485788113695]\n",
            "Validation Accuracy:  [89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 90.72164948453609, 91.75257731958763]\n",
            "Best Hyperparameter:\n",
            "Epoch =  550\n",
            "Alpha =  0.0001\n",
            "Roh =  1e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-Eg8MToVObW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84daa076-25ad-4643-fda6-a8a101875ab3"
      },
      "source": [
        "for i in range(0, 5): # for 5 fold\n",
        "  print(\"For fold no:\", i+1)\n",
        "  print(\"-\"*100)\n",
        "  slp = SingleLayerPerceptron().fit(all_x_train[i], all_y_train[i], epoch = epoch, roh = roh, lr = alpha)\n",
        "  print(\"Accuracy on training data: \" + str(slp.score(all_x_train[i], all_y_train[i])*100) + \"%\")\n",
        "  predicted = slp.predict_classes(all_x_test[i])\n",
        "  print(\"Testing Accuracy Score: \" + str(accuracy_score(all_y_test[i], predicted)*100))\n",
        "  print('Confusion Matrix : \\n' + str(confusion_matrix(all_y_test[i], predicted)))\n",
        "  # out_labels = [1, 2, 3, 4, 5, 6]\n",
        "  print(classification_report(all_y_test[i], predicted,  digits = 6))\n",
        "  print(\"-\"*100)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For fold no: 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 92.14876033057851%\n",
            "Testing Accuracy Score: 90.98360655737704\n",
            "Confusion Matrix : \n",
            "[[  0   7   0]\n",
            " [  0 107   0]\n",
            " [  0   4   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1   0.000000  0.000000  0.000000         7\n",
            "           2   0.906780  1.000000  0.951111       107\n",
            "           3   1.000000  0.500000  0.666667         8\n",
            "\n",
            "    accuracy                       0.909836       122\n",
            "   macro avg   0.635593  0.500000  0.539259       122\n",
            "weighted avg   0.860864  0.909836  0.877887       122\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 91.54639175257732%\n",
            "Testing Accuracy Score: 94.21487603305785\n",
            "Confusion Matrix : \n",
            "[[  0   5   0]\n",
            " [  0 111   1]\n",
            " [  0   1   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1   0.000000  0.000000  0.000000         5\n",
            "           2   0.948718  0.991071  0.969432       112\n",
            "           3   0.750000  0.750000  0.750000         4\n",
            "\n",
            "    accuracy                       0.942149       121\n",
            "   macro avg   0.566239  0.580357  0.573144       121\n",
            "weighted avg   0.902946  0.942149  0.922119       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 91.54639175257732%\n",
            "Testing Accuracy Score: 93.38842975206612\n",
            "Confusion Matrix : \n",
            "[[  0   5   0]\n",
            " [  0 109   1]\n",
            " [  0   2   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1   0.000000  0.000000  0.000000         5\n",
            "           2   0.939655  0.990909  0.964602       110\n",
            "           3   0.800000  0.666667  0.727273         6\n",
            "\n",
            "    accuracy                       0.933884       121\n",
            "   macro avg   0.579885  0.552525  0.563958       121\n",
            "weighted avg   0.893901  0.933884  0.912974       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 91.95876288659794%\n",
            "Testing Accuracy Score: 90.9090909090909\n",
            "Confusion Matrix : \n",
            "[[  0   4   0]\n",
            " [  0 107   3]\n",
            " [  0   4   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1   0.000000  0.000000  0.000000         4\n",
            "           2   0.930435  0.972727  0.951111       110\n",
            "           3   0.500000  0.428571  0.461538         7\n",
            "\n",
            "    accuracy                       0.909091       121\n",
            "   macro avg   0.476812  0.467100  0.470883       121\n",
            "weighted avg   0.874775  0.909091  0.891347       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 92.78350515463917%\n",
            "Testing Accuracy Score: 88.42975206611571\n",
            "Confusion Matrix : \n",
            "[[  0   6   0]\n",
            " [  0 104   3]\n",
            " [  0   5   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1   0.000000  0.000000  0.000000         6\n",
            "           2   0.904348  0.971963  0.936937       107\n",
            "           3   0.500000  0.375000  0.428571         8\n",
            "\n",
            "    accuracy                       0.884298       121\n",
            "   macro avg   0.468116  0.448988  0.455169       121\n",
            "weighted avg   0.832770  0.884298  0.856866       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATDOZ2YqWMgD"
      },
      "source": [
        "# Overfit Detection\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# it's slp\n",
        "class Overfit_SingleLayerPerceptron():\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        return self.predict_(self.add_bias(X))\n",
        "    \n",
        "    def predict_(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        pre_vals = np.dot(X, self.weights.T).reshape(-1, len(np.unique(y)))\n",
        "        return self.softmax(pre_vals)\n",
        "    \n",
        "    def softmax(self, z):\n",
        "        \"\"\"\n",
        "        z: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
        "\n",
        "    def predict_classes(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        self.probs_ = self.predict(X)\n",
        "        return np.vectorize(lambda c: self.classes[c])(np.argmax(self.probs_, axis=1))\n",
        "  \n",
        "    def add_bias(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        return np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "    def one_hot(self, y):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.eye(len(self.classes))[np.vectorize(lambda c: self.class_labels[c])(y).reshape(-1)]\n",
        "    \n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(self.predict_classes(X) == y)\n",
        "    \n",
        "    def evaluate_(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(np.argmax(self.predict_(X), axis=1) == np.argmax(y, axis=1))\n",
        "\n",
        "    def logloss(self, y, probs):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        probs: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(-y*np.log(probs) - (1-y)*np.log(1-probs))\n",
        "\n",
        "    def cross_entropy(self, y, probs):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        probs: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return -1 * np.mean(y * np.log(probs))\n",
        "\n",
        "    def mse(self, y, probs):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        probs: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return (((y - probs)**2).mean())/2\n",
        "        \n",
        "    def fit(self, X, y, X_validation, y_validation, epoch, roh, lr):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns in training set, no of features)\n",
        "        y: 1D array of shape (no of patterns in training set, )\n",
        "        X_validation: 2D array of shape (no of patterns in validation set, no of features)\n",
        "        y_validation: 1D array of shape (no of patterns in validation set, )\n",
        "        epoch:  int, convergence criteria (hyperparameter)\n",
        "        roh:    float, convergence criteria (hyperparameter)\n",
        "        lr:     float, learning rate (hyperparameter)\n",
        "        \"\"\"\n",
        "        self.epoch = epoch\n",
        "        self.roh = roh\n",
        "        self.lr = lr \n",
        "        self.classes = np.unique(y)\n",
        "        self.class_labels = {c:i for i,c in enumerate(self.classes)}\n",
        "        X = self.add_bias(X)\n",
        "        X_validation  = self.add_bias(X_validation)\n",
        "        y = self.one_hot(y)\n",
        "        y_valid = self.one_hot(y_validation)\n",
        "        self.loss_train = []\n",
        "        self.loss_valid = []\n",
        "        self.weights = np.zeros(shape=(len(self.classes),X.shape[1]))*0.1\n",
        "        self.fit_data(X, y, X_validation, y_valid)\n",
        "        return self\n",
        " \n",
        "    def fit_data(self, X, y, X_validation, y_valid):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns in training set, no of features)\n",
        "        y: 1D array of shape (no of patterns in training set, )\n",
        "        X_validation: 2D array of shape (no of patterns in validation set, no of features)\n",
        "        y_validation: 1D array of shape (no of patterns in validation set, )\n",
        "        \"\"\"\n",
        "        itr = 0\n",
        "        while (not self.epoch or itr < self.epoch):\n",
        "            self.loss_train.append(self.mse(y, self.predict_(X)))\n",
        "            self.loss_valid.append(self.mse(y_valid, self.predict_(X_validation)))\n",
        "            # put the thershold function on the predicted value i.e. here self.predict_(X)\n",
        "            temp = self.predict_(X)\n",
        "            # threshold activation on the predicted value of all patterns\n",
        "            for k in range(0, temp.shape[0]):\n",
        "              for j in range(0, temp.shape[1]):\n",
        "                if(temp[k][j]>=0.5):\n",
        "                  temp[k][j] = 1\n",
        "                else:\n",
        "                  temp[k][j] = 0\n",
        "            #print(\"Iteration: \", itr+1, \" Mse: \", self.mse(y, self.predict_(X)))\n",
        "            error = y - temp\n",
        "            update = (self.lr * np.dot(error.T, X))\n",
        "            self.weights += update\n",
        "            if np.abs(update).max() < self.roh:\n",
        "              print(\"Converged through roh criteria.\")\n",
        "              break\n",
        "            itr +=1\n",
        "        if(itr==self.epoch):\n",
        "          print(\"Converged through maximum of Iteration:\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "b1zvuTX20Brr",
        "outputId": "08a9ffdb-3eeb-4286-a17f-3d33e5bdb644"
      },
      "source": [
        "oslp = Overfit_SingleLayerPerceptron().fit(X_train, y_train, X_validation, y_validation, epoch, alpha, roh)\n",
        "print(\"Accuracy on training data: \" + str(oslp.score(X_train, y_train)*100) + \"%\")\n",
        "print(\"-\"*100)\n",
        "test_predicted = oslp.predict_classes(all_x_test[0])\n",
        "print(\"Testing Accuracy Score: \" + str(accuracy_score(all_y_test[0], test_predicted)*100))\n",
        "print(\"Testing Confusion Matrix : \\n\" + str(confusion_matrix(all_y_test[0], test_predicted)))\n",
        "print(\"-\"*100)\n",
        "valid_predicted = oslp.predict_classes(X_validation)\n",
        "print(\"Validation Accuracy Score: \" + str(accuracy_score(y_validation, valid_predicted)*100))\n",
        "print(\"Validation Confusion Matrix : \\n\" + str(confusion_matrix(y_validation, valid_predicted)))\n",
        "print(\"-\"*100)\n",
        "loss_train_mse = oslp.loss_train\n",
        "loss_valid_mse = oslp.loss_valid\n",
        "def plotting(x, y_1, y_2, label_1, label_2, t):\n",
        "  plt.plot(x, y_1, label = label_1)\n",
        "  plt.plot(x, y_2, label = label_2)\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Training and Validation MSE\")\n",
        "  plt.legend()\n",
        "  plt.title(t)\n",
        "  plt.savefig(\"slp_overfit.pdf\")\n",
        "  plt.show()\n",
        "x = []\n",
        "for i in range(0, len(loss_valid_mse)):\n",
        "  x.append(i)\n",
        "plotting(x, loss_train_mse, loss_valid_mse, \"Training MSE\", \"Validation MSE\", \"Training and Validation MSE\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 90.95607235142118%\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Testing Accuracy Score: 87.70491803278688\n",
            "Testing Confusion Matrix : \n",
            "[[  0   7   0]\n",
            " [  0 107   0]\n",
            " [  0   8   0]]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Validation Accuracy Score: 89.69072164948454\n",
            "Validation Confusion Matrix : \n",
            "[[ 0  8  0]\n",
            " [ 0 87  0]\n",
            " [ 0  2  0]]\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuQ4u7T-0uXD"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waIgYJW-WJ--"
      },
      "source": [
        "# Sigmoid Neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Uvq9nJWMri"
      },
      "source": [
        "# it's Sigmoid neuron\n",
        "class SigmoidNeuron():\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        return self.predict_(self.add_bias(X))\n",
        "    \n",
        "    def predict_(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        pre_vals = np.dot(X, self.weights.T).reshape(-1,len(self.classes))\n",
        "        return self.softmax(pre_vals)\n",
        "    \n",
        "    def softmax(self, z):\n",
        "        \"\"\"\n",
        "        z: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
        "\n",
        "    def predict_classes(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        self.probs_ = self.predict(X)\n",
        "        return np.vectorize(lambda c: self.classes[c])(np.argmax(self.probs_, axis=1))\n",
        "  \n",
        "    def add_bias(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        return np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "    def one_hot(self, y):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.eye(len(self.classes))[np.vectorize(lambda c: self.class_labels[c])(y).reshape(-1)]\n",
        "    \n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(self.predict_classes(X) == y)\n",
        "    \n",
        "    def evaluate_(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(np.argmax(self.predict_(X), axis=1) == np.argmax(y, axis=1))\n",
        "\n",
        "    def logloss(self, y, probs):\n",
        "        \"\"\"\n",
        "        y:      1D array of shape (no of patterns, )\n",
        "        probs:  1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(-y*np.log(probs) - (1-y)*np.log(1-probs))\n",
        "\n",
        "    def cross_entropy(self, y, probs):\n",
        "        \"\"\"\n",
        "        y:      1D array of shape (no of patterns, )\n",
        "        probs:  1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return -1 * np.mean(y * np.log(probs))\n",
        "\n",
        "    def mse(self, y, probs):\n",
        "        \"\"\"\n",
        "        y:      1D array of shape (no of patterns, )\n",
        "        probs:  1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return (((y - probs)**2).mean())/2\n",
        "        \n",
        "    def fit(self, X, y, epoch, roh, lr):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns in training set, no of features)\n",
        "        y: 1D array of shape (no of patterns in training set, )\n",
        "        epoch:  int, convergence criteria (hyperparameter)\n",
        "        roh:    float, convergence criteria (hyperparameter)\n",
        "        lr:     float, learning rate (hyperparameter)\n",
        "        \"\"\"\n",
        "        self.epoch = epoch\n",
        "        self.roh = roh\n",
        "        self.lr = lr \n",
        "        self.classes = np.unique(y)\n",
        "        self.class_labels = {c:i for i,c in enumerate(self.classes)}\n",
        "        X = self.add_bias(X)\n",
        "        y = self.one_hot(y)\n",
        "        self.loss = []\n",
        "        self.weights = np.zeros(shape=(len(self.classes),X.shape[1]))*0.1\n",
        "        self.fit_data(X, y)\n",
        "        return self\n",
        " \n",
        "    def fit_data(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        itr = 0\n",
        "        while (not self.epoch or itr < self.epoch):\n",
        "            self.loss.append(self.mse(y, self.predict_(X)))\n",
        "            # put the thershold function on the predicted value i.e. here self.predict_(X)\n",
        "            temp = self.predict_(X)\n",
        "            #print(\"Iteration: \", itr+1, \" Mse: \", self.mse(y, self.predict_(X)))\n",
        "            error = y - temp\n",
        "            update = (self.lr * np.dot(error.T, X))\n",
        "            self.weights += update\n",
        "            if np.abs(update).max() < self.roh:\n",
        "              print(\"Converged through roh criteria.\")\n",
        "              break\n",
        "            itr +=1\n",
        "        if(itr==self.epoch):\n",
        "          print(\"Converged through maximum of Iteration:\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQR0_7J1LHZ"
      },
      "source": [
        "# hyperparameter tuning\n",
        "def sn_hyperparameter_tuning(epoch, alpha, roh, X_train, X_validation, y_train, y_validation):\n",
        "  val_acc = []\n",
        "  train_acc = []\n",
        "  for i in range(0, epoch.shape[0]):\n",
        "    # we are taking logloss function for error calculation\n",
        "    sn_classifier = SigmoidNeuron().fit(X_train, y_train, epoch = epoch[i], roh = roh[i], lr = alpha[i])\n",
        "    predicted = sn_classifier.predict_classes(X_validation)\n",
        "    val_acc.append(accuracy_score(y_validation, predicted)*100)\n",
        "    train_predicted = sn_classifier.predict_classes(X_train)\n",
        "    train_acc.append(accuracy_score(y_train, train_predicted)*100)\n",
        "  # Get the maximum accuracy on validation\n",
        "  print(\"Training Accuracy: \", train_acc)\n",
        "  print(\"Validation Accuracy: \", val_acc)\n",
        "  # Get the maximum accuracy on validation\n",
        "  max_value = max(val_acc)\n",
        "  max_index = val_acc.index(max_value)\n",
        "  best_hyperparameter = (epoch[max_index], alpha[max_index], roh[max_index])\n",
        "  print(\"Best Hyperparameter:\")\n",
        "  print(\"Epoch = \", epoch[max_index])\n",
        "  print(\"Alpha = \", alpha[max_index])\n",
        "  print(\"Roh = \", roh[max_index])\n",
        "  return best_hyperparameter"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgvCLco_1UhF",
        "outputId": "b2f40eaf-b6a0-459b-a3ca-92288c6baab2"
      },
      "source": [
        "epoch = np.array([100, 150, 200, 250, 300, 350, 400, 450, 500, 550])\n",
        "alpha = np.array([0.0001, 0.0001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.0001, 0.0001])\n",
        "roh = np.array([0.00001, 0.00001, 0.000001, 0.0000001, 0.000001, 0.0001, 0.0001, 0.0001, 0.0001, 0.000001])\n",
        "epoch, alpha, roh = sn_hyperparameter_tuning(epoch, alpha, roh, X_train, X_validation, y_train, y_validation)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Converged through maximum of Iteration:\n",
            "Training Accuracy:  [90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118, 90.95607235142118]\n",
            "Validation Accuracy:  [89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454, 89.69072164948454]\n",
            "Best Hyperparameter:\n",
            "Epoch =  100\n",
            "Alpha =  0.0001\n",
            "Roh =  1e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVYXCUsY1fWQ",
        "outputId": "6c474194-154c-4ff6-e921-c0c1d0226624"
      },
      "source": [
        "for i in range(0, 5): # for 5 fold\n",
        "  print(\"For fold no:\", i+1)\n",
        "  print(\"-\"*100)\n",
        "  sn = SigmoidNeuron().fit(all_x_train[i], all_y_train[i], epoch = epoch, roh = roh, lr = alpha)\n",
        "  print(\"Accuracy on training data: \" + str(sn.score(all_x_train[i], all_y_train[i])*100) + \"%\")\n",
        "  predicted = sn.predict_classes(all_x_test[i])\n",
        "  print(\"Testing Accuracy Score: \" + str(accuracy_score(all_y_test[i], predicted)*100))\n",
        "  print('Confusion Matrix : \\n' + str(confusion_matrix(all_y_test[i], predicted)))\n",
        "  print(classification_report(all_y_test[i], predicted))\n",
        "  print(\"-\"*100)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For fold no: 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 90.70247933884298%\n",
            "Testing Accuracy Score: 87.70491803278688\n",
            "Confusion Matrix : \n",
            "[[  0   7   0]\n",
            " [  0 107   0]\n",
            " [  0   8   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.88      1.00      0.93       107\n",
            "           3       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.88       122\n",
            "   macro avg       0.29      0.33      0.31       122\n",
            "weighted avg       0.77      0.88      0.82       122\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 89.48453608247424%\n",
            "Testing Accuracy Score: 92.56198347107438\n",
            "Confusion Matrix : \n",
            "[[  0   5   0]\n",
            " [  0 112   0]\n",
            " [  0   4   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       0.93      1.00      0.96       112\n",
            "           3       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.93       121\n",
            "   macro avg       0.31      0.33      0.32       121\n",
            "weighted avg       0.86      0.93      0.89       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 89.89690721649485%\n",
            "Testing Accuracy Score: 90.9090909090909\n",
            "Confusion Matrix : \n",
            "[[  0   5   0]\n",
            " [  0 110   0]\n",
            " [  0   6   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       0.91      1.00      0.95       110\n",
            "           3       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.91       121\n",
            "   macro avg       0.30      0.33      0.32       121\n",
            "weighted avg       0.83      0.91      0.87       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 89.89690721649485%\n",
            "Testing Accuracy Score: 90.9090909090909\n",
            "Confusion Matrix : \n",
            "[[  0   4   0]\n",
            " [  0 110   0]\n",
            " [  0   7   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.91      1.00      0.95       110\n",
            "           3       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.91       121\n",
            "   macro avg       0.30      0.33      0.32       121\n",
            "weighted avg       0.83      0.91      0.87       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 90.51546391752578%\n",
            "Testing Accuracy Score: 88.42975206611571\n",
            "Confusion Matrix : \n",
            "[[  0   6   0]\n",
            " [  0 107   0]\n",
            " [  0   8   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.88      1.00      0.94       107\n",
            "           3       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.88       121\n",
            "   macro avg       0.29      0.33      0.31       121\n",
            "weighted avg       0.78      0.88      0.83       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E3JlVHx1faN"
      },
      "source": [
        "# Overfit Detection\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# it's slp\n",
        "class Overfit_SigmoidNeuron():\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        return self.predict_(self.add_bias(X))\n",
        "    \n",
        "    def predict_(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        pre_vals = np.dot(X, self.weights.T).reshape(-1, len(np.unique(y)))\n",
        "        return self.softmax(pre_vals)\n",
        "    \n",
        "    def softmax(self, z):\n",
        "        \"\"\"\n",
        "        z: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
        "\n",
        "    def predict_classes(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        self.probs_ = self.predict(X)\n",
        "        return np.vectorize(lambda c: self.classes[c])(np.argmax(self.probs_, axis=1))\n",
        "  \n",
        "    def add_bias(self, X):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        \"\"\"\n",
        "        return np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "    def one_hot(self, y):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.eye(len(self.classes))[np.vectorize(lambda c: self.class_labels[c])(y).reshape(-1)]\n",
        "    \n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(self.predict_classes(X) == y)\n",
        "    \n",
        "    def evaluate_(self, X, y):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns, no of features)\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(np.argmax(self.predict_(X), axis=1) == np.argmax(y, axis=1))\n",
        "\n",
        "    def logloss(self, y, probs):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        probs: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return np.mean(-y*np.log(probs) - (1-y)*np.log(1-probs))\n",
        "\n",
        "    def cross_entropy(self, y, probs):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        probs: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return -1 * np.mean(y * np.log(probs))\n",
        "\n",
        "    def mse(self, y, probs):\n",
        "        \"\"\"\n",
        "        y: 1D array of shape (no of patterns, )\n",
        "        probs: 1D array of shape (no of patterns, )\n",
        "        \"\"\"\n",
        "        return (((y - probs)**2).mean())/2\n",
        "        \n",
        "    def fit(self, X, y, X_validation, y_validation, epoch, roh, lr):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns in training set, no of features)\n",
        "        y: 1D array of shape (no of patterns in training set, )\n",
        "        X_validation: 2D array of shape (no of patterns in validation set, no of features)\n",
        "        y_validation: 1D array of shape (no of patterns in validation set, )\n",
        "        epoch:  int, convergence criteria (hyperparameter)\n",
        "        roh:    float, convergence criteria (hyperparameter)\n",
        "        lr:     float, learning rate (hyperparameter)\n",
        "        \"\"\"\n",
        "        self.epoch = epoch\n",
        "        self.roh = roh\n",
        "        self.lr = lr \n",
        "        self.classes = np.unique(y)\n",
        "        self.class_labels = {c:i for i,c in enumerate(self.classes)}\n",
        "        X = self.add_bias(X)\n",
        "        X_validation  = self.add_bias(X_validation)\n",
        "        y = self.one_hot(y)\n",
        "        y_valid = self.one_hot(y_validation)\n",
        "        self.loss_train = []\n",
        "        self.loss_valid = []\n",
        "        self.weights = np.zeros(shape=(len(self.classes),X.shape[1]))*0.1\n",
        "        self.fit_data(X, y, X_validation, y_valid)\n",
        "        return self\n",
        " \n",
        "    def fit_data(self, X, y, X_validation, y_valid):\n",
        "        \"\"\"\n",
        "        X: 2D array of shape (no of patterns in training set, no of features)\n",
        "        y: 1D array of shape (no of patterns in training set, )\n",
        "        X_validation: 2D array of shape (no of patterns in validation set, no of features)\n",
        "        y_validation: 1D array of shape (no of patterns in validation set, )\n",
        "        \"\"\"\n",
        "        itr = 0\n",
        "        while (not self.epoch or itr < self.epoch):\n",
        "            self.loss_train.append(self.mse(y, self.predict_(X)))\n",
        "            self.loss_valid.append(self.mse(y_valid, self.predict_(X_validation)))\n",
        "            # put the thershold function on the predicted value i.e. here self.predict_(X)\n",
        "            temp = self.predict_(X)\n",
        "            #print(\"Iteration: \", itr+1, \" Mse: \", self.mse(y, self.predict_(X)))\n",
        "            error = y - temp\n",
        "            update = (self.lr * np.dot(error.T, X))\n",
        "            self.weights += update\n",
        "            if np.abs(update).max() < self.roh:\n",
        "              print(\"Converged through roh criteria.\")\n",
        "              break\n",
        "            itr +=1\n",
        "        if(itr==self.epoch):\n",
        "          print(\"Converged through maximum of Iteration:\")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkeWf1W_1xQt",
        "outputId": "ce2e995e-6927-4937-fa17-72c6edeb6012"
      },
      "source": [
        "osn = Overfit_SigmoidNeuron().fit(X_train, y_train, X_validation, y_validation, epoch, alpha, roh)\n",
        "print(\"Accuracy on training data: \" + str(osn.score(X_train, y_train)*100) + \"%\")\n",
        "print(\"-\"*100)\n",
        "test_predicted = osn.predict_classes(all_x_test[0])\n",
        "print(\"Testing Accuracy Score: \" + str(accuracy_score(all_y_test[0], test_predicted)*100))\n",
        "print(\"Testing Confusion Matrix : \\n\" + str(confusion_matrix(all_y_test[0], test_predicted)))\n",
        "print(\"-\"*100)\n",
        "valid_predicted = osn.predict_classes(X_validation)\n",
        "print(\"Validation Accuracy Score: \" + str(accuracy_score(y_validation, valid_predicted)*100))\n",
        "print(\"Validation Confusion Matrix : \\n\" + str(confusion_matrix(y_validation, valid_predicted)))\n",
        "print(\"-\"*100)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged through maximum of Iteration:\n",
            "Accuracy on training data: 90.95607235142118%\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Testing Accuracy Score: 87.70491803278688\n",
            "Testing Confusion Matrix : \n",
            "[[  0   7   0]\n",
            " [  0 107   0]\n",
            " [  0   8   0]]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Validation Accuracy Score: 89.69072164948454\n",
            "Validation Confusion Matrix : \n",
            "[[ 0  8  0]\n",
            " [ 0 87  0]\n",
            " [ 0  2  0]]\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "5sYb3ZCM1xwC",
        "outputId": "fcb7d022-6211-4d52-a3ab-dbc9acb8336c"
      },
      "source": [
        "loss_train_mse = osn.loss_train\n",
        "loss_valid_mse = osn.loss_valid\n",
        "def plotting(x, y_1, y_2, label_1, label_2, t):\n",
        "  plt.plot(x, y_1, label = label_1)\n",
        "  plt.plot(x, y_2, label = label_2)\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Training and Validation MSE\")\n",
        "  plt.legend()\n",
        "  plt.title(t)\n",
        "  plt.savefig(\"sn_overfit.pdf\")\n",
        "  plt.show()\n",
        "x = []\n",
        "for i in range(0, len(loss_valid_mse)):\n",
        "  x.append(i)\n",
        "plotting(x, loss_train_mse, loss_valid_mse, \"Training MSE\", \"Validation MSE\", \"Training and Validation MSE\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDxSpuKK1x1O"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIQdZiooWYAA"
      },
      "source": [
        "# MLP (with one hidden layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3hOn6WaWTmV"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkeXOVgyWgY5"
      },
      "source": [
        "# hyperparameter tuning for logistic accuracy\n",
        "def mlp_hyperparameter_tuning(no_of_hidden_neurons, epoch, alpha, roh, n_iter_no_change, X_train, X_validation, y_train, y_validation):\n",
        "  val_acc = []\n",
        "  for i in range(0, epoch.shape[0]):\n",
        "    mlp_classifier = MLPClassifier(hidden_layer_sizes = (no_of_hidden_neurons[i],), activation = 'logistic', solver = 'sgd', learning_rate = 'constant',\\\n",
        "      learning_rate_init = alpha[i], max_iter = epoch[i], shuffle = True, random_state = 100, tol = roh[i],\\\n",
        "      verbose = False, early_stopping = True, n_iter_no_change = n_iter_no_change[i]).fit(X_train, y_train)\n",
        "    # we are taking logloss function for error calculation\n",
        "    predicted = mlp_classifier.predict(X_validation)\n",
        "    val_acc.append(accuracy_score(y_validation, predicted)*100)\n",
        "  # Get the maximum accuracy on validation\n",
        "  max_value = max(val_acc)\n",
        "  max_index = val_acc.index(max_value)\n",
        "  best_hyperparameter = (no_of_hidden_neurons[max_index], epoch[max_index], alpha[max_index], roh[max_index], n_iter_no_change[max_index])\n",
        "  print(\"Best Hyperparameter:\")\n",
        "  print(\"No of neurons in the 1st hidden layer = \", no_of_hidden_neurons[max_index])\n",
        "  print(\"Epoch = \", epoch[max_index])\n",
        "  print(\"Alpha = \", alpha[max_index])\n",
        "  print(\"Roh = \", roh[max_index])\n",
        "  print(\"n_iter_no_change (Number of iterations with no improvement) = \", n_iter_no_change[max_index])\n",
        "  return best_hyperparameter"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNSypCP52Pbu",
        "outputId": "ee4646aa-23f2-4c3a-baed-98f56941b14b"
      },
      "source": [
        "no_of_hidden_neurons = np.array([561, 581, 591, 600, 620, 650, 670, 700, 730, 750])\n",
        "epoch = np.array([100, 150, 200, 250, 300, 350, 400, 450, 500, 550])\n",
        "alpha = np.array([0.01, 0.001, 0.0001, 0.00001, 0.125, 0.15, 0.18, 0.2, 0.25, 0.3])\n",
        "roh = np.array([0.00001, 0.00001, 0.000001, 0.0000001, 0.000001, 0.0001, 0.0001, 0.0001, 0.0001, 0.000001])\n",
        "n_iter_no_change = np.array([8, 9, 10, 11, 12, 13, 14, 15, 16, 18])\n",
        "no_of_hidden_neurons, epoch, alpha, roh, n_iter_no_change = mlp_hyperparameter_tuning(no_of_hidden_neurons, epoch, alpha, roh, n_iter_no_change, X_train, X_validation, y_train, y_validation)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameter:\n",
            "No of neurons in the 1st hidden layer =  561\n",
            "Epoch =  100\n",
            "Alpha =  0.01\n",
            "Roh =  1e-05\n",
            "n_iter_no_change (Number of iterations with no improvement) =  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USOgTUxBbI8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf5b4bd-9e76-4db9-a968-49aaee7b8de9"
      },
      "source": [
        "for i in range(0, 5): # for 5 fold\n",
        "  print(\"For fold no:\", i+1)\n",
        "  print(\"-\"*100)\n",
        "  mlp_classifier = MLPClassifier(hidden_layer_sizes = (no_of_hidden_neurons,), activation = 'logistic',\\\n",
        "                                 solver = 'sgd', learning_rate = 'constant', learning_rate_init = alpha,\\\n",
        "                                 max_iter = epoch, shuffle = True, random_state = 100, tol = roh,\\\n",
        "                            verbose = False, early_stopping = True, n_iter_no_change = n_iter_no_change)\n",
        "  mlp_classifier.fit(all_x_train[i], all_y_train[i])\n",
        "  print(\"Accuracy on training data: \" + str(mlp_classifier.score(all_x_train[i], all_y_train[i])*100) + \"%\")\n",
        "  predicted = mlp_classifier.predict(all_x_test[i])\n",
        "  print(\"Testing Accuracy Score: \" + str(accuracy_score(all_y_test[i], predicted)*100))\n",
        "  print(\"Confusion Matrix : \\n\" + str(confusion_matrix(all_y_test[i], predicted)))\n",
        "  print(\"Classification Report for 6-classes: \")\n",
        "  # out_labels = [1, 2, 3, 4, 5, 6]\n",
        "  print(classification_report(all_y_test[i], predicted,  digits=4))\n",
        "  print(\"-\"*100)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For fold no: 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 90.70247933884298%\n",
            "Testing Accuracy Score: 87.70491803278688\n",
            "Confusion Matrix : \n",
            "[[  0   7   0]\n",
            " [  0 107   0]\n",
            " [  0   8   0]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000         7\n",
            "           2     0.8770    1.0000    0.9345       107\n",
            "           3     0.0000    0.0000    0.0000         8\n",
            "\n",
            "    accuracy                         0.8770       122\n",
            "   macro avg     0.2923    0.3333    0.3115       122\n",
            "weighted avg     0.7692    0.8770    0.8196       122\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 89.48453608247424%\n",
            "Testing Accuracy Score: 92.56198347107438\n",
            "Confusion Matrix : \n",
            "[[  0   5   0]\n",
            " [  0 112   0]\n",
            " [  0   4   0]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000         5\n",
            "           2     0.9256    1.0000    0.9614       112\n",
            "           3     0.0000    0.0000    0.0000         4\n",
            "\n",
            "    accuracy                         0.9256       121\n",
            "   macro avg     0.3085    0.3333    0.3205       121\n",
            "weighted avg     0.8568    0.9256    0.8899       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 89.89690721649485%\n",
            "Testing Accuracy Score: 90.9090909090909\n",
            "Confusion Matrix : \n",
            "[[  0   5   0]\n",
            " [  0 110   0]\n",
            " [  0   6   0]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000         5\n",
            "           2     0.9091    1.0000    0.9524       110\n",
            "           3     0.0000    0.0000    0.0000         6\n",
            "\n",
            "    accuracy                         0.9091       121\n",
            "   macro avg     0.3030    0.3333    0.3175       121\n",
            "weighted avg     0.8264    0.9091    0.8658       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 89.89690721649485%\n",
            "Testing Accuracy Score: 90.9090909090909\n",
            "Confusion Matrix : \n",
            "[[  0   4   0]\n",
            " [  0 110   0]\n",
            " [  0   7   0]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000         4\n",
            "           2     0.9091    1.0000    0.9524       110\n",
            "           3     0.0000    0.0000    0.0000         7\n",
            "\n",
            "    accuracy                         0.9091       121\n",
            "   macro avg     0.3030    0.3333    0.3175       121\n",
            "weighted avg     0.8264    0.9091    0.8658       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "For fold no: 5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy on training data: 90.51546391752578%\n",
            "Testing Accuracy Score: 88.42975206611571\n",
            "Confusion Matrix : \n",
            "[[  0   6   0]\n",
            " [  0 107   0]\n",
            " [  0   8   0]]\n",
            "Classification Report for 6-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000         6\n",
            "           2     0.8843    1.0000    0.9386       107\n",
            "           3     0.0000    0.0000    0.0000         8\n",
            "\n",
            "    accuracy                         0.8843       121\n",
            "   macro avg     0.2948    0.3333    0.3129       121\n",
            "weighted avg     0.7820    0.8843    0.8300       121\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6usvEuU2oYB",
        "outputId": "479c3613-fbe4-4340-990b-61512e756bb4"
      },
      "source": [
        "# Is there any overfit issue?\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes = (no_of_hidden_neurons,), activation = 'logistic',\\\n",
        "                                solver = 'sgd', learning_rate = 'constant', learning_rate_init = alpha,\\\n",
        "                                max_iter = epoch, shuffle = True, random_state = 100, tol = roh,\\\n",
        "                                verbose = False, early_stopping = True, n_iter_no_change = n_iter_no_change)\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "print(\"Accuracy on training data: \" + str(mlp_classifier.score(X_train, y_train)*100) + \"%\")\n",
        "print(\"-\"*100)\n",
        "test_predicted = mlp_classifier.predict(all_x_test[0])\n",
        "print(\"Testing Accuracy Score: \" + str(accuracy_score(all_y_test[0], test_predicted)*100))\n",
        "print(\"Testing Confusion Matrix : \\n\" + str(confusion_matrix(all_y_test[0], test_predicted)))\n",
        "print(\"-\"*100)\n",
        "valid_predicted = mlp_classifier.predict(X_validation)\n",
        "print(\"Validation Accuracy Score: \" + str(accuracy_score(y_validation, valid_predicted)*100))\n",
        "print(\"Validation Confusion Matrix : \\n\" + str(confusion_matrix(y_validation, valid_predicted)))\n",
        "print(\"-\"*100)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training data: 90.95607235142118%\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Testing Accuracy Score: 87.70491803278688\n",
            "Testing Confusion Matrix : \n",
            "[[  0   7   0]\n",
            " [  0 107   0]\n",
            " [  0   8   0]]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Validation Accuracy Score: 89.69072164948454\n",
            "Validation Confusion Matrix : \n",
            "[[ 0  8  0]\n",
            " [ 0 87  0]\n",
            " [ 0  2  0]]\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}